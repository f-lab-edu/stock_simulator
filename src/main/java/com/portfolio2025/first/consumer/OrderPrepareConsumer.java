package com.portfolio2025.first.consumer;

import com.fasterxml.jackson.core.JsonProcessingException;
import com.fasterxml.jackson.databind.ObjectMapper;
import com.portfolio2025.first.domain.Order;
import com.portfolio2025.first.domain.order.OrderType;
import com.portfolio2025.first.domain.stock.StockOrder;
import com.portfolio2025.first.dto.event.OrderCreatedEvent;
import com.portfolio2025.first.repository.OrderRepository;
import com.portfolio2025.first.service.KafkaProducerService;
import com.portfolio2025.first.service.OrderPrepareService;
import lombok.RequiredArgsConstructor;
import lombok.extern.slf4j.Slf4j;
import org.springframework.kafka.annotation.KafkaListener;
import org.springframework.kafka.support.Acknowledgment;
import org.springframework.stereotype.Component;

/**
 * Îß§ÎèÑ, Îß§Ïàò Ï£ºÎ¨∏ Topic Íµ¨ÎèÖ
 * Order Í≤ÄÏ¶ù ÏßÑÌñâÌïòÍ∏∞ -> Redis Î∞òÏòÅ
 *
 */


@Component
@RequiredArgsConstructor
@Slf4j
public class OrderPrepareConsumer {

    private final OrderRepository orderRepository;
    private final OrderPrepareService orderPrepareService;
    private final KafkaProducerService kafkaProducerService;
    private final ObjectMapper objectMapper;


    @KafkaListener(
            topics = "order.created",
            groupId = "order-prepare-group",
            concurrency ="2",
            containerFactory = "stringKafkaListenerContainerFactory"
    )
    public void consumeOrderCreated(String message, Acknowledgment ack) throws InterruptedException {
        log.info("üü¢ Kafka Received: {}", message);

        OrderCreatedEvent event = null;
        try {
            event = objectMapper.readValue(message, OrderCreatedEvent.class);
            log.info("üü¢ Parsed OrderCreatedEvent: {}", event);
        } catch (JsonProcessingException e) {
            log.error("‚ùå Failed to parse JSON", e);
            return;
        }

        Order order = null;
        int retry = 0;
        while (retry < 5) {
            order = orderRepository.findByIdWithStockOrders(event.getOrderId()).orElse(null);
            log.info("üîÅ Try {}: order = {}", retry, order);
            if (order != null)
                break;
            Thread.sleep(200);
            retry++;
        }

        if (order == null) {
            log.error("‚ùå Order not found in DB even after retries: orderId={}", event.getOrderId());
            return;
        }

        if (order.getStockOrders() == null) {
            log.error("‚ùå StockOrders is NULL");
            return;
        }

        if (order.getStockOrders().isEmpty()) {
            log.error("‚ùå StockOrders is EMPTY");
            return;
        }

        try {
            for (StockOrder stockOrder : order.getStockOrders()) {
                log.info("üü¢ Validating stockOrder: {}", stockOrder.getId());
                // RedisÏóê Î∞òÏòÅ (Ï£ºÎ¨∏ ÌïòÎÇòÎùºÎèÑ Î∞òÏòÅÎêòÎäî ÏàúÍ∞Ñ Kafka Ïù¥Î≤§Ìä∏ ÏöîÏ≤≠Ìï¥ÏÑú matchÎ•º ÏöîÏ≤≠Ìï®)
                orderPrepareService.validateAndRegisterToRedis(stockOrder, OrderType.valueOf(event.getOrderType()));
                // Ï≤¥Í≤∞ÏùÑ ÏúÑÌïú Kafka Ïù¥Î≤§Ìä∏ ÏöîÏ≤≠
                kafkaProducerService.publishMatchRequest(stockOrder.getStock().getStockCode());
            }


        } catch (Exception e) {
            // ‚ùå Ïª§Î∞ãÌïòÏßÄ ÏïäÏùå ‚Üí Ïû¨Ï≤òÎ¶¨ ÎåÄÏÉÅ
            log.error("‚ùå Error while processing stockOrders: {}", e.getMessage());
            // Ïû¨Î∞úÌñâÌïòÎäî Í≤ΩÏö∞ IdempotencyÎäî Ïñ¥ÎñªÍ≤å Íµ¨ÏÑ±Ìï†ÏßÄ ÏÉùÍ∞ÅÌï† Ïàò ÏûàÏñ¥Ïïº Ìï®.
        } finally {
            // ‚úÖ Î™®Îì† Ï≤òÎ¶¨ ÏôÑÎ£å ÌõÑ Ïª§Î∞ã
            ack.acknowledge();
            log.info("‚úÖ Kafka offset manually committed");
        }
    }
}
